Metadata-Version: 2.4
Name: langgraph-sdk-aipy
Version: 0.1.61
Summary: SDK for interacting with LangGraph API
Author-email: The QPYPI Team <qpypi@qpython.org>
License: MIT AND (Apache-2.0 OR BSD-2-Clause)
Project-URL: Homepage, https://qpypi.qpython.org/project/langgraph-sdk-aipy/
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Education
Classifier: Intended Audience :: Information Technology
Classifier: Intended Audience :: End Users/Desktop
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: Android
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development
Requires-Python: ==3.12.*
Description-Content-Type: text/markdown
Requires-Dist: httpx
Requires-Dist: orjson-qpython
Requires-Dist: langgraph-aipy

This project is a branch of [langgraph-sdk](https://pypi.org/project/langgraph-sdk/) on [QPython](https://www.qpython.org).

# LangGraph Python SDK

This repository contains the Python SDK for interacting with the LangGraph Cloud REST API.

## Quick Start

To get started with the Python SDK, [install the package](https://pypi.org/project/langgraph-sdk/)

```bash
pip install -U langgraph-sdk
```

You will need a running LangGraph API server. If you're running a server locally using `langgraph-cli`, SDK will automatically point at `http://localhost:8123`, otherwise
you would need to specify the server URL when creating a client.

```python
from langgraph_sdk import get_client

# If you're using a remote server, initialize the client with `get_client(url=REMOTE_URL)`
client = get_client()

# List all assistants
assistants = await client.assistants.search()

# We auto-create an assistant for each graph you register in config.
agent = assistants[0]

# Start a new thread
thread = await client.threads.create()

# Start a streaming run
input = {"messages": [{"role": "human", "content": "what's the weather in la"}]}
async for chunk in client.runs.stream(thread['thread_id'], agent['assistant_id'], input=input):
    print(chunk)
```
