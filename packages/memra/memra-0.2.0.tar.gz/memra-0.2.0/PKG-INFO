Metadata-Version: 2.4
Name: memra
Version: 0.2.0
Summary: Declarative framework for enterprise workflows with MCP integration
Home-page: https://github.com/memra/memra-sdk
Author: Memra
Author-email: Memra <info@memra.co>
License: MIT
Project-URL: Homepage, https://memra.co
Project-URL: Repository, https://github.com/memra-platform/memra-sdk
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: pydantic>=1.8.0
Requires-Dist: httpx>=0.24.0
Requires-Dist: typing-extensions>=4.0.0
Requires-Dist: aiohttp>=3.8.0
Requires-Dist: aiohttp-cors>=0.7.0
Requires-Dist: psycopg2-binary>=2.9.0
Provides-Extra: dev
Requires-Dist: pytest>=6.0; extra == "dev"
Requires-Dist: pytest-asyncio; extra == "dev"
Requires-Dist: black; extra == "dev"
Requires-Dist: flake8; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# Memra SDK

A declarative orchestration framework for AI-powered business workflows. Think of it as "Kubernetes for business logic" where agents are the pods and departments are the deployments.

## ğŸš€ Team Setup

**New team member?** See the complete setup guide: **[TEAM_SETUP.md](TEAM_SETUP.md)**

This includes:
- Database setup (PostgreSQL + Docker)
- Local development environment
- Testing instructions
- Troubleshooting guide

## Quick Start

```python
from memra.sdk.models import Agent, Department, Tool

# Define your agents
data_extractor = Agent(
    role="Data Extraction Specialist",
    job="Extract and validate data",
    tools=[Tool(name="DataExtractor", hosted_by="memra")],
    input_keys=["input_data"],
    output_key="extracted_data"
)

# Create a department
dept = Department(
    name="Data Processing",
    mission="Process and validate data",
    agents=[data_extractor]
)

# Run the workflow
result = dept.run({"input_data": {...}})
```

## Installation

```bash
pip install memra
```

## API Access

Memra requires an API key to execute workflows on the hosted infrastructure.

### Get Your API Key
Contact [info@memra.co](mailto:info@memra.co) for API access.

### Set Your API Key
```bash
# Set environment variable
export MEMRA_API_KEY="your-api-key-here"

# Or add to your shell profile for persistence
echo 'export MEMRA_API_KEY="your-api-key-here"' >> ~/.zshrc
```

### Test Your Setup
```bash
python examples/accounts_payable_client.py
```

## Documentation

Documentation is coming soon. For now, see the examples below and in the `examples/` directory.

## Example: Propane Delivery Workflow

See the `examples/propane_delivery.py` file for a complete example of how to use Memra to orchestrate a propane delivery workflow.

## Contributing

We welcome contributions! Please see our [contributing guide](CONTRIBUTING.md) for details.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## Examples

```
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ accounts_payable_client.py  # API-based example
â”‚   â”œâ”€â”€ accounts_payable.py         # Local example
â”‚   â”œâ”€â”€ invoice_processing.py       # Simple workflow
â”‚   â””â”€â”€ propane_delivery.py         # Domain example
â”œâ”€â”€ memra/                  # Core SDK
â”œâ”€â”€ logic/                  # Tool implementations  
â”œâ”€â”€ local/dependencies/     # Database setup & schemas
â””â”€â”€ docker-compose.yml      # Database setup
```

## âœ¨ New: MCP Integration

Memra now supports **Model Context Protocol (MCP)** integration, allowing you to execute operations on your local infrastructure while leveraging Memra's cloud-based AI processing.

**Key Benefits:**
- ğŸ”’ **Keep sensitive data local** - Your databases stay on your infrastructure
- âš¡ **Hybrid processing** - AI processing in the cloud, data operations locally  
- ğŸ” **Secure communication** - HMAC-authenticated requests between cloud and local
- ğŸ› ï¸ **Easy setup** - Simple bridge server connects your local resources

**Quick Example:**
```python
# Agent that uses local database via MCP
agent = Agent(
    role="Data Writer",
    tools=[{
        "name": "PostgresInsert",
        "hosted_by": "mcp",  # Routes to your local infrastructure
        "config": {
            "bridge_url": "http://localhost:8081",
            "bridge_secret": "your-secret"
        }
    }]
)
```

ğŸ“– **[Complete MCP Integration Guide â†’](docs/mcp_integration.md)**
