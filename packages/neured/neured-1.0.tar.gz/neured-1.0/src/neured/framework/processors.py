# ******************************************************************

#                           PROCESSORS

# Collection of functions to perform batch image processing

# ******************************************************************

    # import functions from img_utils
from neured.framework.img_utils import show_img, get_img, crop_img, write_img
from neured.framework.file_utils import file_list, change_ext, file_index, write_results, add_tag, \
    get_tag, change_tag, read_file
import numpy as np
import os
from tqdm.notebook import tqdm
from neured.framework.parameters import param, get_all_params, set_group_scope

def exec_start():
    
    import getpass
    from datetime import datetime
    
    start_time = datetime.now()
    
    print(datetime.strftime(start_time, "%d.%m.%Y - %H:%M:%S") + ' - Processing start (user: \'' + getpass.getuser() + '\')')
    
    return start_time
    
def exec_end(start_time, it_count=0):
    
    from datetime import datetime
    
    end_time = datetime.now()
    
    print(datetime.strftime(end_time, "%d.%m.%Y - %H:%M:%S") + ' - Processing complete')
    print('Elapsed time: ' + (str(end_time-start_time)).split('.')[0])
    if it_count != 0:
        print('Iteration count: ' + str(it_count))
        print('Time per iteration: ' + ("%.2f" % ((end_time-start_time)/it_count).total_seconds()) + 's')

# ------------------------------------------------------------------
#                           load_img_params
# ------------------------------------------------------------------
# this function loops through a list of parameters, identifies any parameter
# whose name ends with '_imgf' as an image file names, load the corresponding
# images and return a new parameters list including the images themselves. The
# parameters including the images have the same name as the file name parameters,
# but with the ending changed to '_img'

# This function is not to be called directly from the notebook, but is called
# automatically from the 'batch_proc' and 'test_proc' functions. 

# input parameters: base_dir = directory relative to which the file names
#                               are specified (absolute path is used if omitted)
#                   **kwargs = collection of named parameters

# return value: new collection of named parameters including the loaded images
# ------------------------------------------------------------------

def load_img_params(base_dir='', **kwargs):
    """
    this function loops through a list of parameters, identifies any parameter
    whose name ends with '_imgf' as an image file names, load the corresponding
    images and return a new parameters list including the images themselves. The
    parameters including the images have the same name as the file name parameters,
    but with the ending changed to '_img'

    Parameters
    ----------
    base_dir : string
       directory relative to which the file names are specified
       (absolute path is used if omitted)
    **kwargs : dictionnary
        collection of named parameters

    Returns
    -------
    new_kwargs : TYPE
        new collection of named parameters including the loaded images

    """
    from neured.framework.parameters import param
    import numpy as np
    
    log_level = 'standard' if param('log_level') is None else param('log_level')
    
        # create a new instance of the parameters list
    new_kwargs = kwargs.copy()
   
        # loop through all parameters
    for key, value in kwargs.items():
        
            # if any parameter name ends with '_imgf' it is a file name definition
            # or a function returning a file name
        if key.endswith('_imgf'):
            
            if log_level == 'debug':
                print('Image file parameter: {:s}, value={:s}'.format(key, value))
            
                # a new parameter name is generated by changing the ending to '__imgloaded'
            imgloaded_key = key.rpartition('_imgf')[0] + '__imgloaded' 
            
            if imgloaded_key in kwargs.keys() and log_level == 'debug':
                print('imgloaded key value: {:s}'.format(kwargs[imgloaded_key]))
            
                # test if the image is already loaded
            if imgloaded_key in kwargs.keys() and kwargs[imgloaded_key] == value:
                    
                if log_level == 'debug':
                    print('Image already loaded')
                    
                pass
            
            else:
                
                        # if not done yet, the corresponding image is loaded if the file exists
                if value is not None and os.path.isfile(os.path.join(base_dir, value)): 
                    img, header = get_img(value, base_dir, get_header=True)
                        # or the value or the corresponding image is set to None if the file doesn't exist
            
                    if log_level == 'debug':
                        print('Image loaded')
                        print('Shape: ' + str(img.shape))
                        print('Min value: ' + str(np.min(img)))
                        print('Max value: ' + str(np.max(img)))
                        print('Avg value: ' + str(np.mean(img)))
                        
                else:
                    img = None
                    
                    if log_level == 'debug':
                        print('Image not loaded')
                
                    # a new parameter name is generated by changing the ending to '_img'
                new_key = key.rpartition('_imgf')[0] + '_img'     
                new_key_header = key.rpartition('_imgf')[0] + '_imghd'               
                
                    # and the loaded image is assigned to this parameter
                new_kwargs[new_key] = img
                new_kwargs[new_key_header] = header
                
                    # update the parameter indicating which image was loaded
                new_kwargs[imgloaded_key] = value
    
        # return the new list of parameters
    return new_kwargs

#---------------------------------------------------------------------------

def load_dyn_params(current_file, base_dir='', **kwargs):
    """
    
    this function loops through a list of parameters and identifies any parameter
    whose name ends with '_imgf' and is callable. In that case, the corresponding
    function is called to return the name of an image file. The corresponding image
    is loaded and stored in a parameter with the same name but ending with '_img'.
    
    This function is not to be called directly but is used as a sub-function is the
    batch_proc() function and others.

    Parameters
    ----------
    current_file : string
        Current source file name.
    base_dir : string
        base directory.
    **kwargs : dictionnary
        List of named parameters.

    Returns
    -------
    new_kwargs : dictonnary
        New list of named parameters.

    """
    
    import pandas
    from fnmatch import fnmatch
    
        # indicator of whether any LUT parameter was updated
    lut_param_updated = False
    
        # create a new instance of the parameters list
    new_kwargs = kwargs.copy()
   
        # loop through all parameters
    for key, value in kwargs.items():
        
            # if any parameter name ends with '_lut', it is a dynamic parameter
        if key.endswith('_lut'):
            
                # a new parameter name is generated by removing the '_lut' string
            new_key = key.rpartition('_lut')[0]
            
                # compute the parameter name corresponding to the LUT as a pandas
                # dataframe
            df_key = key + '_df'
            
                # if the LUT as a dataframe is not in the parameters yet
            if df_key not in new_kwargs.keys():
                
                    # load the look up table in a data frame and save it in the parameters
                new_kwargs[df_key] = pandas.read_csv(os.path.join(base_dir, value), delimiter=';')
                
                # get the LUT dataframe
            lut_df = new_kwargs[df_key]
               
                # check which lines match with the source file name
            matches = [fnmatch(current_file, x) for x in lut_df['src']]
                
                # if no match is found, return an error
            if not any(matches):
                raise ValueError('Source file "' + current_file +
                                 '" does not match any line of the lookup table for parameter "' +
                                 new_key + '"')
                
                # get the index of the first match
            imatch = np.where(matches)[0][0]
            
                # store the corresponding parameter value
            new_kwargs[new_key] = lut_df['val'][imatch]
    
                # indicate that a parameter was updated
            lut_param_updated = True
    
        # if any LUT parameter was updated, reload the image parameters
        # (in case an image name has changed)
    if lut_param_updated:
        new_kwargs = load_img_params(base_dir, **new_kwargs)
            
        # return the new list of parameters
    return new_kwargs
    

# ------------------------------------------------------------------
#                           load_imgdir_params
# ------------------------------------------------------------------
# this function loops through a list of parameters, identifies any parameter
# whose name ends with '_imgd' as an image directory, load the corresponding
# images and return a new parameters list including the images themselves. The
# parameters including the images have the same name as the "stack" name parameters,
# but with the ending changed to '_img'

# This function is not to be called directly from the notebook, but is called
# automatically from the 'batch_proc' and 'test_proc' functions. 

# input parameters: base_dir = directory relative to which the file names
#                               are specified (absolute path is used if omitted)
#                   current_file = currently processed file
#                   **kwargs = collection of named parameters

# return value: new collection of named parameters including the loaded images
# ------------------------------------------------------------------

def load_imgdir_params(current_file, base_dir='', imgd_repl=[], **kwargs):
    
    import os
    
        # create a new instance of the parameters list
    new_kwargs = kwargs.copy()
   
        # loop through all parameters
    for key, value in kwargs.items():
        
            # if any parameter name ends with '_imgd' it is an image directory definition
        if key.endswith('_imgd'):
            
            mod_fname = current_file
            
            for repl_elem in imgd_repl:
                s1, _, s2 = mod_fname.rpartition(repl_elem[0])
                mod_fname = s1 + repl_elem[1] + s2
            
                # get the name of the 
            img_fname = os.path.join(value, mod_fname)
            
                # in this case, the corresponding image is loaded
            img = get_img(img_fname, base_dir)
            
                # a new parameter name is generated by changing the ending to '_img'
            head, _, _ = key.rpartition('_imgd')
            
                # and the loaded image is assigned to this parameter
            new_key = head + '_img'            
            new_kwargs[new_key] = img
            
    new_kwargs['imgd_repl'] = imgd_repl
    
        # return the new list of parameters
    return new_kwargs

# ------------------------------------------------------------------
#                        cleanup_img_buffer
# ------------------------------------------------------------------
# This function is called regularly (each time a new step is processed)
# to actualize the image buffer. The 'last_used' indication of each processed
# image is incremented, and if more image are stored than the allowed number,
# the ones which have been used since the longest time are removed from the
# buffer.

# input parameters: img_buffer = dictionnary containing the processed images
#                   max_img = maximum number of images which can be stored in
#                               the buffer

# return value: none (img_buffer is modified directly)
# ------------------------------------------------------------------

def cleanup_img_buffer(max_img=100, **kwargs):
           
    img_buffer = kwargs['img_buffer']
    
        # Test if debug is activated for this function
    debug = False
    if 'debug' in kwargs.keys():
        if 'cleanup_img_buffer' in kwargs['debug']:
            debug = True
            
        # list of the already processed images, for sorting by last use
    lu_list = []
    
        # loop over all images and steps
    for fname, value in img_buffer.items():
        for snum, proc_state in enumerate(value):
            
                # if this step has been computed for a particular image
            if proc_state['computed']:
            
                    # increment the 'last used' indicator
                proc_state['last_used'] = proc_state['last_used'] + 1
                
                    # put the information in the processed images list
                lu_list.append((proc_state['last_used'], fname, snum))
        
    if debug:
        print('--- cleanup_img_buffer() ---')
        print('Buffer size: ', len(lu_list), ' / Max. size: ', max_img)
            
        # if more than the allowed number of processed images is stored
    if len(lu_list) > max_img:
        
        
            # sort the list (image with the longest time since last use first)
        lu_list.sort(reverse=True)
        
            # remove the oldest images to free memory space
        for i in range(len(lu_list) - max_img):
            fname = (lu_list[i])[1]
            snum = (lu_list[i])[2]
            ((img_buffer[fname])[snum])['img'] = np.zeros([0,0])
            ((img_buffer[fname])[snum])['computed'] = False
            ((img_buffer[fname])[snum])['last_used'] = 0
                
            if debug:
                print('Image "', fname, '", step ', snum, ' removed')
            
    return
    
# ------------------------------------------------------------------
#                           get_proc_img
# ------------------------------------------------------------------
# This function is used to obtain an image (defined by its full path) at
# a defined stage of the processing. It first looks into an image buffer whether
# this image was already processed for this stage. If not, it either loads the
# image (if the initial stage is required) or computes the image from the previous stage

# This function is used recursively, as it will call itself for an earlier stage
# of processing unless the initial stage is required. It is meant, together with
# the 'get_neighbors_stack' function, to provide an optimal mechanism for 3D
# filtering and data processing

# input parameters: img_fname = full path of the corresponding source image
#                   proc_seq = array of processing functions
#                   step = stage of the processing for which the image is desired
#                           0 = source image, 1 = after first step, 2 = after second step, ...
#                   img_buffer = buffer containing the images already processed
#                   **kwargs = list of names parameters

# return value: the image after the processing has been applied
# -----------------------------------------------------------------------------    
def get_proc_img(img_fname, step, get_header=False, **kwargs):
    
    def buffer_size(img_buffer):
        
        sz = 0
        
        for fname, value in img_buffer.items():
            for snum, proc_state in enumerate(value):
                if proc_state['computed']:
                    sz = sz + 1
        
        return sz
        
    
        # Test if debug is activated for this function
    debug = False
    if 'debug' in kwargs.keys():
        if 'get_proc_img' in kwargs['debug']:
            debug = True
            
    img_buffer = kwargs['img_buffer']
    proc_seq = kwargs['proc_seq']
            
        # check if an element with this file name exists in the buffer
    if img_fname in img_buffer.keys():
        
            # if yes, check if the desired step is already computed
        if ((img_buffer[img_fname])[step])['computed']:
        
                # output debug information if necessary
            if debug:
                print('----- get_proc_img() -----')
                print('file name: ', img_fname)
                print('step: ', step)
                print('buffer size:', buffer_size(img_buffer))
                print('Required image already in buffer')
            
                # if computed, return the image (indicate that it has been used)
            ((img_buffer[img_fname])[step])['last_used'] = 0   
            
                # if the header is required, return image and header
            if get_header:
                return ((img_buffer[img_fname])[step])['img'], ((img_buffer[img_fname])[step])['header']
            
                # otherwise return only the image
            else:
                return ((img_buffer[img_fname])[step])['img']
            
        # if no element with this file name exists, create it
    else:
        buf_base = {'computed':False, 'img':0, 'header':None, 'last_used':0}
        img_buffer[img_fname] = [buf_base.copy() for x in range(len(proc_seq)+1)]
        
        # if the step value is 0, we need the initial image (without processing)
    if step == 0:
        img, header = get_img(img_fname, get_header=True)
        
            # output debug information if necessary
        if debug:
            print('----- get_proc_img() -----')
            print('file name: ', img_fname)
            print('step: ', step)
            print('buffer size:', buffer_size(img_buffer))
            print('Source image loaded')
        
        # otherwise, the image is computed from the result of the previous step
    else:
        kwargs_proc = kwargs.copy()
        kwargs_proc['current_step'] = step-1
        kwargs_proc['current_fname'] = img_fname
        
            # require the resulting image of the previous step
        img_prev, header_prev = get_proc_img(img_fname, step-1, get_header=True, **kwargs)
        
            # get the header after the previous step
        kwargs_proc['header'] = header_prev.copy()
        
            # if the result of the previous step is valid
        if img_prev.size > 0:
            
                # compute the step
            img = proc_seq[step-1](img_prev, **kwargs_proc)
                # get the header after the processing step
            header = kwargs_proc['header']
            
                # output debug information if necessary
            if debug:
                print('----- get_proc_img() -----')
                print('file name: ', img_fname)
                print('step: ', step)
                print('buffer size:', buffer_size(img_buffer))
                if img.size > 0:
                    print('Processing step ', step, ' applied successfully')
                else:
                    print('Processing step ', step, ' gave an empty result')
        
            # if the result of the previous step is not valid
        else:
            
                # return an empty image
            img = np.zeros([0,0])
        
                # use the previous header
            header = header_prev.copy()
            
                # output debug information if necessary
            if debug:
                print('----- get_proc_img() -----')
                print('file name: ', img_fname)
                print('step: ', step)
                print('buffer size:', buffer_size(img_buffer))
                print('The image after previous step is not valid')
    
        # store the obtained image in the buffer
    (img_buffer[img_fname])[step] = {'computed':True, 'img':img, 'header':header, 'last_used':0}
    
        # perform the buffer cleanup
    cleanup_img_buffer(**kwargs)
    
    if debug:
        print('img: ', img)
        print('header: ', header)
    
        # if the header was requested, return the image and header            
    if get_header:
        return img, header
    
        # otherwise return only the image
    else:
        return img
                
# -----------------------------------------------------------------------------
#                           get_neighbor_imgf
# -----------------------------------------------------------------------------
# This function looks from a 'neighbor' image of a file within a diretory.
# The neighbor image needs to have the same name expect for the last "tag"
# (part of the file after the last occurence of '_') assumed to be defining
# the file index. The file index of the searched neighbor is computed usig the
# specified offset.

# input parameters: fname = file from which the neighboring files are to be found
#                   offet = offset of the index relative to current file (negative
#                           or positive)

# return value: if the neighboring file is found, its complete path is returned
#               otherwise, an empty string is returned
# -----------------------------------------------------------------------------
    
def get_neighbor_imgf(fname, offset):
    
        # get the file index tag
    index_str = get_tag(fname, tag_pos=-1)
    
        # get the length of the tag
    l = len(index_str)
    
        # get the index value
    index = int(index_str)
    
        # compute the new index tage including the offset
    new_index_str = format(index + offset, '0'+str(l)+'d')
    
        # compute the neighbor file name
    n_fname = change_tag(fname, new_index_str, tag_pos=-1)
    
        # if the neighbor file exists, return the path
    if os.path.exists(n_fname):
        return n_fname
    
        # otherwise return an empty string
    else:
        return ''
                
# -----------------------------------------------------------------------------
#                           get_neighbors_stack
# -----------------------------------------------------------------------------
# This function can be called from within an image processing function to add
# the possibility of performing 3D filtering or data processing. It will return
# a stack of images centered on the current image. All processing steps which
# are before the current processing step are applied to each image of the stack.
        
# This function should only be called within a processing function which was
# called from the Pyerre framework (e.g. by 'batch_proc' or 'simple_merge'),
# as the '**kwargs' argument needs to contain the current processing information.

# input parameters: size = number of images in the stack (should be an odd number)
#                   **kwargs = list of named parameters (contains in particular
#                               the information about the current state of processing)

# return value: a 3D numpy array containing the stack of images. If any
#               neighboring image is not existing, and empty stack is returned
# -----------------------------------------------------------------------------
        
def get_neighbors_stack(size, **kwargs):
    
        # get the buffer and current processing information from the list
        # of named argument
    current_fname = kwargs['current_fname']
    current_step = kwargs['current_step']
    
        # compute the names of the neighboring images (the function also checks if the files exist)
    img_names = [get_neighbor_imgf(current_fname, off) for off in range(int(-size/2), int(-size/2)+size)]
    
        # if any neighbor is invalid or not found, returns an empty stack
    if '' in img_names:
        return np.zeros([0,0,0])

    else:
        
        first_img = True
        
        for imgf in img_names:
            
                # get the processed neighbor image
            img, _ = get_proc_img(imgf, current_step, get_header=True, **kwargs)
            
                # if this is the first image of the stack, create the 3D image stack
            if first_img:
                stack = np.expand_dims(img, 2)
                first_img = False
                # otherwise, add the image to the stack
            else:
                stack = np.dstack((stack, img))
        
            # return the stack
        return stack
        

# ------------------------------------------------------------------
#                           exec_proc
# ------------------------------------------------------------------
# This function applies a defined sequence of image processing steps to an image.
    
# Each processing step should be a function accepting an image (2D array) as
# the first parameter, plus an undefined count of named parameters, and returning
# the processed image.
    
# The processing steps are applied in the order defined in the 'seq' array. It is
# possible to apply only a subset of the sequence by using the parameters 'start_before',
# 'start_after', 'stop_before' and 'stop_after'.
    
# This function is normally not called directly from the notebook, but is used
# as a sub-function of 'batch_proc'

# input parameters: src_img = 2D array containing the source image (used only if
#                               the 'allow_3D' parameter is False)
#                   seq = array with a list of processing functions to be applied
#                   start_before = indicates that the starting point of the processing
#                                   sequence is just before this function (this parameter
#                                   has priority over 'start_after')
#                   start_after = indicates that the starting point of the processing
#                                   sequence is just after this function
#                   stop_before = indicates that the ending point of the processing
#                                   sequence is just before this function (this parameter
#                                   has priority over 'stop_after')
#                   stop_after = indicates that the ending point of the processing
#                                   sequence is just after this function
#                   allow_3D = if true, 3D processing functions are allowed and they
#                               can get the "neighborhood" stack using the function
#                               'get_neighbors_stack()'
#                   src_fname = complete path of the source image file (used only if
#                               the 'allow_3D' parameter is True)
#                   **kwargs = collection of additional named parameters

# return value: new collection of named parameters including the loaded images
# ------------------------------------------------------------------

def exec_proc(src_img, seq, proc_from=None, proc_to=None, start_before=0, start_after=0,
              stop_before=0, stop_after=0, allow_3D=False, src_fname='',
              get_header=False, header=None, **kwargs):
    
    # 'start_before', 'start_after', and so on ... kept now backward compatibility
    # will be removed as soon as new notebooks don't need them.
    
        # if 'start_before' or 'start_after' is defined, identify at which step to start,
        # otherwise start at the first step of the sequence
    if start_before != 0:
        first_step = seq.index(start_before)
    elif start_after != 0:
        first_step = seq.index(start_after) + 1
    else:
        first_step = 0
        
        # if 'stop_before' or 'stop_after' is defined, identify at which step to stop,
        # otherwise stop at the last step of the sequence
    if stop_before != 0:
        last_step = seq.index(stop_before)
    elif stop_after != 0:
        last_step = seq.index(stop_after) + 1
    else:
        last_step = len(seq)
        
        # find the index of the start milestone, if any
    if proc_from is not None:
       try:
           first_step = seq.index(proc_from)
       except ValueError:
           raise ValueError('Start milestone "'+proc_from+'" not found in processing sequence')
        
        # find the index of the end milestone, if any
    if proc_to is not None:
       try:
           last_step = seq.index(proc_to)
       except ValueError:
           raise ValueError('End milestone "'+proc_to+'" not found in processing sequence')
        
        # extract the selected subset of the processing sequence and remove
        # the milestones to keep only the functions
    proc_seq = [step for step in seq[first_step:last_step] if not isinstance(step, str)]
    
        # if the 3D compatible mode is activated
    if allow_3D:
        
            # create the image buffer dictionary if this wasn't done yet
        if 'img_buffer' not in kwargs.keys():
            kwargs['img_buffer'] = {}
            
        kwargs['proc_seq'] = proc_seq
        
            # use the 'get_proc_img()' function to require the result of
            # the last processing steps. All other steps are called recursively
        if get_header:
            img, header = get_proc_img(src_fname, len(proc_seq), get_header=True, **kwargs)
        else:
            img = get_proc_img(src_fname, len(proc_seq), **kwargs)
        
        # if the 3D mode is not activated, just apply the steps sequentially
    else:
    
            # create an copy of the source image
        img = src_img.copy()
        
            # apply succesively all processing steps to the image
        for step in proc_seq:
            img = step(img, header=header, **kwargs)
    
        # if the header was requested, return the image and header            
    if get_header:
        return img, header
    
        # otherwise return only the image
    else:
        return img



# ------------------------------------------------------------------
#                           test_proc
# ------------------------------------------------------------------
# This function is used to test a processing sequence on a limited
# subset of the source images. Instead of writing the processed images
# to the disk, they are displayed (e.g. in a notebook calling this function).
#
# It is possible to define one of the named parameters (in **kwargs) as being
# a test parameter, with a set of testing values. In this case, the processing
# will be performed once for each of the testing values.
#
# input parameters: src_dir = source directory (relative to 'base_dir')
#                   seq = sequence of processing steps (see the details of the
#                       'exec_proc' function)
#                   base_dir = base directory to define the relative paths
#                   nimg = number of test images on which the processing is
#                       applied (default is 10)
#                   test_param = if specified, name of the parameter whose
#                       value is being tested
#                   test_values = list of values to be tested for the parameter
#                       defined by 'test_param'
#                   ftype = source file type (default is 'fits')
#                   **kwargs = additional list of named parameters. **kwargs will
#                           be passed to different sub functions, but in particular:
#                   - All values defined in **kwargs are made available to
#                     the processing steps
#                   - All parameters in **kwargs whose name ends with '_imgf'
#                     are assumed to be image file names. The corresponding images
#                     are loaded and made available to the processing steps
#                     as named parameters with the '_imgf' ending changed to 'img'
#                   - The 'start_before', 'start_after', 'stop_before' and
#                     'stop_after' parameters are passed to the 'exec_proc'
#                     function and can be used to define a subset of the
#                     processing sequence to be applied.
#                   - The 'roi' and 'disp_rect' params can be used as defined in
#                     the 'batch_proc' function
#                   
# return value: none
# ------------------------------------------------------------------

def test_proc(src, seq, nimg=10, test_param='', test_values=(),
              ftype='fits', wmax=750, ncols=1, **kwargs):
    
    import matplotlib.pyplot as plt
    from collections.abc import Iterable
    
        # check the skip testing mode (this mode allows to speed up the
        # repeated execution of notebooks)
    if param('skip_testing') == True:
        
            # if activated, do not perform the test processing
        print('Skip testing mode activated')
        return
    
    index = 0
    
        # if a test parameter is defined
    if test_param != '':
        
        nimg_tot = len(test_values)*nimg
        nrows = ((nimg_tot-1) // ncols) + 1
        
            # loop for all values to be tried for the test parameter
        for param_val in tqdm(test_values, desc='Testing parameters'):
            
                # create a copy of the named parameters list and apply the
                # current value to the test parameter
            new_kwargs = kwargs.copy()
            new_kwargs[test_param] = param_val
            
                # convert the test parameter value to a string with a precision of 5 significant digits max.
            try:
                    # case of a list, array or tuple parameter
                if isinstance(param_val, Iterable):
                    param_val_str = '[' + ', '.join(['{0:.5g}'.format(x) for x in param_val]) + ']'
                    # case of a single value parameter
                else:
                    param_val_str = '{0:.5g}'.format(param_val)
                    
                # if the conversion failed, use the more generic str() conversion
                # function (but all digits will be printed, which may lead to excessive length)
            except ValueError:
                param_val_str = str(param_val)
            
                # create a title string specifying the parameter value
            param_title = test_param + ' = ' + param_val_str
            
                # only show the image name if there are several images
            if nimg == 1:
                show_name = False
            else:
                show_name = True
        
                # apply the batch processing in testing mode with this parameter value
            batch_proc(src, '', seq, test=nimg, show_title=param_title, ftype=ftype,
                       wmax=wmax, show_name=show_name, ncols=ncols, nrows=nrows, param_index=index, 
                       **new_kwargs)       
            
            index += 1
        
        # if no test parameter is specified, apply the batch processing in
        # testing mode without affecting the parameter values
    else:
            # compute the number of necessary rows
        nrows = ((nimg-1) // ncols) + 1
        
            # perform the test processing
        batch_proc(src, '', seq, test=nimg, ftype=ftype, param_index=index,
                   wmax=wmax, ncols=ncols, nrows=nrows, **kwargs)
        
    plt.show()
        
#------------------------------------------------------------------------------        

def single_proc(src, dst, seq, ftype='fits', **kwargs):
    '''
    --------------------------- single_proc -----------------------------------
    
    Executes a processing sequence on a single file and writes the destination

    Parameters
    ----------
    src_fname : string
        Source file name (relative to base_dir).
    dst_fname : string
        Destination file name (relative to base_dir).
    seq : list of functions
        Definition of the processing steps.
    base_dir : string
        Base directory (absolute path).
    roi : list of integers, optional
        Region of interest, image is cropped to this after the processing.
        Format: [x0, y0, width, height]. The default is [0,0,0,0] (= full image).
    ftype : String, optional
        Definition of the file type. The default is 'fits'.
    **kwargs : dictionnary
        additional list of named parameters. **kwargs will
        be passed to different sub functions, but in particular:
            - All values defined in **kwargs are made available to
              the processing steps
            - All parameters in **kwargs whose name ends with '_imgf'
              are assumed to be image file names. The corresponding images
              are loaded and made available to the processing steps
              as named parameters with the '_imgf' ending changed to 'img'
            - The 'start_before', 'start_after', 'stop_before' and
              'stop_after' parameters are passed to the 'exec_proc'
              function and can be used to define a subset of the
              processing sequence to be applied..

    Returns
    -------
    None.

    '''
        # call the batch processing function in single processing mode
    batch_proc('', '', seq, ftype=ftype, src_fname=src, dst_fname=dst, **kwargs)
    
# ------------------------------------------------------------------
#                           batch_proc
# ------------------------------------------------------------------
# This function applies a sequence of processing steps to all FITS files
# in a folder and its subfolders. The same hierarchy of sub-folder as found
# in the source directory is created in the destination directory.
        
# In testing mode, the processed images are not saved but displayed

# In single processing mode, only one image is processed
        
# input parameters: src_dir = source directory (relative to 'base_dir')
#                   dst_dir = destination directory (relative to 'base_dir')
#                   seq = sequence of processing steps (see the details of the
#                           'exec_proc' function)
#                   base_dir = base directory to define the relative paths
#                   test = if 0 (default), the script is executed in normal
#                           mode. If not zero, defines the number of images
#                           on which the processing is to be tested
#                   roi = rectangle defining the region of
#                           interest. Only this region is saved or displayed
#                           after the processing.
#                   show_title = string to be added in the title when displaying
#                           the images (only relevant in testing mode)
#                   disp_rect = list of parameters defining a rectangle which have
#                           to be displayed as overlays to the image (only
#                           relevant in testing mode)
#                   ftype = source file type (default is 'fits')
#                   index_range = range of image indexes to be processed [min, max]
#                   tag_pos = position of the file name tag defining the index (default: last)
#                   show_scale = scale for displaying the image in testing mode
#                   src_fname = name of the source file in single processing mode
#                   dst_fname = name of the destination file in single processing mode
#                   **kwargs = additional list of named parameters. **kwargs will
#                           be passed to different sub functions, but in particular:
#                   - All values defined in **kwargs are made available to
#                     the processing steps
#                   - All parameters in **kwargs whose name ends with '_imgf'
#                     are assumed to be image file names. The corresponding images
#                     are loaded and made available to the processing steps
#                     as named parameters with the '_imgf' ending changed to 'img'
#                   - The 'start_before', 'start_after', 'stop_before' and
#                     'stop_after' parameters are passed to the 'exec_proc'
#                     function and can be used to define a subset of the
#                     processing sequence to be applied.
#
#
# return value: none
# ------------------------------------------------------------------
    
def batch_proc(src, dst, seq, test=0, show_title='', disp_rect=[], 
               ftype='fits', index_range=[], interval=1, tag_pos=-1, show_scale=[1.0,1.0], wmax=500,
               src_fname='', dst_fname='', overwrite=False, show_name=True, nrows=1, ncols=1, 
               param_index=1, group='', **kwargs):
    
        # import packages
    import os
    import warnings
    import numpy as np
    import pandas
    
    if test == 0:
        time_start = exec_start()
        
        # empy list for parameter logging
    param_log = []
        
    if group != '':
        set_group_scope(group)
        
        # get all the general processing parameters and add them to kwargs
        # if the same name is present in both, kwargs has the priority
    params = get_all_params()
    kwargs_p = {**params, **kwargs}
    
        # get the log level value
    log_level = 'standard' if param('log_level') is None else param('log_level')
    
    base_dir = kwargs_p['base_dir']
    if 'roi' in kwargs_p.keys():
        roi_val = kwargs_p['roi']
    else:
        roi_val = None
        
        # create the processed images buffer
    kwargs_p['img_buffer'] = {}
    
        # load the images which are used as parameters
        # (see detailed description of the 'load_img_params' function)
    kwargs_img = load_img_params(**kwargs_p)
    
        # if no source directory is defined, we are in single file mode
    if src == '':
            # the file list is composed of a single image
        flist = [src_fname]
        
        # otherwise, we are in normal 'batch' mode
    else:
            # get the list of all FITS files in the specified source directory
            # (including in its subdirectories)
        flist = file_list(src, base_dir, ftype)
        
        # sort the file list
    flist.sort()
            
        # get the number of files in the list
    nfiles = len(flist)
    
    if log_level == 'debug':
        print('Number of files: ', str(nfiles))
    
        # when in testing mode, keep only a limited image count (defined
        # by the value of the 'test' variable)
    if test > 0:
        keep = ((np.arange(test)+0.5)*((nfiles-1)/test)).astype('int')
        if log_level == 'debug':
            print('Keep indexes: ' + str(keep))
        keep_list = [flist[i] for i in keep]
        
        # when not in testing mode and the overwrite option is off
    elif not overwrite and src != '':
            # keep only the files where the destination does not exist
        keep_list = [x for x in flist if not os.path.exists(os.path.join(os.path.join(base_dir, dst), x))]
        
            # output the indication of the number of skipped files, if any
        skipped = nfiles - len(keep_list)
        if skipped > 0:
            print(str(skipped) + ' files out of ' + str(nfiles) +
                  ' were skipped because the destination does already exist')
    
        # if overwrite is on, keep the whole list
    else:
        keep_list = flist
    
        # get the number of kept files
    nkeep = len(keep_list)
    
        # if the keep list is empty, skip the processing
    if nkeep == 0:
        print('No files to process')
        
        # otherwise execute the processing loop
    else:
        
            # initialize the batch and sequence variables
        bvar = {}
        svar = {}
        
            # initialize the last directory indication
        last_dir = ''
      
            # initialize the file index
        i = 0
        
            # create the iterator
        it_desc = 'Processing' if test == 0 else ('Testing' if show_title == '' else 'Testing (' + show_title + ')')
        iterator = keep_list if len(keep_list) == 1 else tqdm(keep_list, desc=it_desc)
        
            # loop for all files in the kept list
        for name in iterator: 
            
            if log_level == 'debug':
                print('Processing file: "' + name + '"')
                    
                # get the current directory
            cur_dir, _ = os.path.split(name)
            
                # if the directory has changed, reset the sequence variables
            if cur_dir != last_dir: svar = {}
            
                # get the file index
            fi = file_index(name, tag_pos)
            
                # if an index range is defined, test whether the current file is in range
            do_proc = 1
            if index_range != []:
                if fi < index_range[0] or fi > index_range[1]:
                    do_proc = 0
            if interval != 1:
                if (fi % interval) != 0: do_proc = 0
            
                # if the current file has to be processed:
            if do_proc:
        
                    # load the images which are used as dynamical parameters
                    # (see detailed description of the 'load_img_params_dyn' function)
                kwargs_img = load_dyn_params(os.path.join(src, name), base_dir, **kwargs_img)
                
                    # if not in testing mode, 
                if test == 0:
                    
                        # compute the destination file name with full path
                    if src == '':
                        dst_name = os.path.join(base_dir, dst_fname)
                    else:
                        dst_name = os.path.join(os.path.join(base_dir, dst), name)
                    
                        # get the destination directory
                    dst_name_dir, _ = os.path.split(dst_name)
                    
                        # and create this destination directory if it does not exist
                    if not os.path.exists(dst_name_dir):
                        os.makedirs(os.path.join(dst_name_dir,''))
                
                    # compute the path of the source image
                src_fname = os.path.join(base_dir, src, name)
                
                    # pass the file index to the processing functions
                kwargs_img['fi'] = fi
                
                    # append the parameters (converted to strings) in the
                    # kwargs log
                param_log_line = {'fname':src_fname}
                
                for key, value in kwargs_img.items():
                    param_log_line[key] = str(value)[:200].replace('\r', '').replace('\n', '')
                    
                param_log.append(param_log_line)
                
                    # disable the warnings occuring during the processing
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    
                        # apply the processing sequence 'seq' to the loaded image 
                        # (see the function 'exec_proc' for details)
                    dst_img, header = exec_proc(0, seq, bvar=bvar, svar=svar, allow_3D=True,
                                    src_fname=src_fname, get_header=True, **kwargs_img)
                    
                    # if a ROI is defined, crop the processed image (only if valid)
                if dst_img.size > 0 and roi_val is not None:
                    dst_img = crop_img(dst_img, roi_val)
                    
                    # output debug information about the destination image
                if log_level == 'debug':
                    print('Destination image shape: ', dst_img.shape)
                    if dst_img.size > 0:
                        print('Destination image min (ignoring NaN): ', np.nanmin(dst_img))
                        print('Destination image max (ignoring NaN): ', np.nanmax(dst_img))
                        print('Destination image average (ignoring NaN): ', np.nanmean(dst_img))
                    
                    # if not in testing mode
                if test == 0:
                    
                        # if the result is valid
                    if dst_img.size > 0:
                        
                            # write the destination image
                        write_img(dst_img, change_ext(dst_name, 'fits'),
                                  header=header, overwrite=overwrite)  
                        
                    
                    # if in testing mode
                else:
                    
                        # if the result is valid
                    if dst_img.size > 0:
                        
                            # generate the image title (name of the image, plus any string
                            # defined in the 'show_title' variable)
                        img_title = name
                        if show_title != '':
                            if show_name:
                                img_title = img_title + '\n' + show_title
                            else:
                                img_title = show_title
                            
                            # extract the list of rectangles to be overlaid
                        dr = []
                        for var_name, color in disp_rect:
                            if var_name in kwargs_p:
                                dr.append((kwargs_p[var_name],color))
                                
                        if (param_index == 0 and i == 0) or (nrows == 1 and ncols == 1):
                            keep_fig = False
                        else:
                            keep_fig = True
                            
                             # display the image   
                        show_img(dst_img, title=img_title, dr=dr, stretch=show_scale, 
                                 keep_fig = keep_fig, wmax=wmax, nrows=nrows, ncols=ncols,
                                 index=param_index*test+i+1, do_show=False)
                        
                        # if the result is not valid, display the info
                    else:
                        print('Result of file: "' + name + '" cannot be shown (processing failed)')
            
                # set the last directory indication for the next iteration
            last_dir = cur_dir
            
                # increase file index
            i = i+1
         
        
    if 'param_log' in kwargs_p.keys():
        
            # create an empty index and list of keys
        plog_index = []
        all_keys = {}
        
            # update the list of all parameter keys and the index
        for param_log_line in param_log:
            plog_index.append(param_log_line['fname'])
            for key in param_log_line.keys():
                all_keys[key] = ''
                
            # create an empty data frame
        df = pandas.DataFrame(all_keys, plog_index)
        
            # add all lines to the dataframe
        for param_log_line in param_log:
            df.loc[param_log_line['fname']] = param_log_line
                    
            # get the destination directory
        log_dir, _ = os.path.split(os.path.join(base_dir, kwargs_p['param_log']))
        
            # and create this destination directory if it does not exist
        if not os.path.exists(log_dir):
                        os.makedirs(os.path.join(log_dir,''))
            
            # save to the CSV file
        df.to_csv(os.path.join(base_dir, kwargs_p['param_log']), sep=';')
    
        # output the execution timing information
    if test == 0:
        exec_end(time_start, len(keep_list))
        
# ------------------------------------------------------------------

def batch_rendering(src, dst, scale=[0,1], cmap='gray', msk=None, base_dir=None,
                    ftype='fits'):
    
    from neured.framework.img_utils import img_render
    import matplotlib.pyplot as plt
    
        # output the start indication
    time_start = exec_start()
        
        # get the base directory from parameters if not defined
    if base_dir is None:
        base_dir = param('base_dir')
        
        # if not mask image is given as a parameter
    if msk is None:
        
            # check if the mask image file is set as a parameter
        if 'render_msk_imgf' in get_all_params().keys():
            
                # if yes, load the mask image
            msk = get_img(param('render_msk_imgf'), base_dir)
    
        # get the list of all FITS files in the specified source directory
        # (including in its subdirectories)
    flist = file_list(src, base_dir, ftype)
    
        # get the number of files
    nfiles = len(flist)
    
        # count of already existing images
    already_exist = 0
    
        # loop for all files
    for fname in tqdm(flist):
    
            # computer the destination file name
        dst_fname = os.path.join(base_dir, dst, os.path.splitext(fname)[0] + '.tif')
        
            # if the destination file does not exist, do the processing
        if not os.path.exists(dst_fname):
            
                # load the image
            img = get_img(os.path.join(src, fname), base_dir=base_dir)
            
                # perform the rendering
            img_rendered = img_render(img, scale=scale, cmap=cmap, msk=msk)
                        
                # get the destination directory
            dst_name_dir, _ = os.path.split(dst_fname)
            
                # and create this destination directory if it does not exist
            if not os.path.exists(dst_name_dir):
                os.makedirs(os.path.join(dst_name_dir,''))
            
                # write the results
            plt.imsave(dst_fname, img_rendered, format='tiff')
            
            # otherwise increment the count of already existing images
        else:
            already_exist = already_exist + 1
            
        # if some files were not processed, output a message
    if already_exist > 0:
        print('{:d} out of {:d} files not processed (destination already exists)'.format(already_exist, nfiles))
        
        # output the end indication
    exec_end(time_start, len(flist))

# ------------------------------------------------------------------
    
def batch_analyse(src_dir, dst_file, base_dir, a_func, pre_proc=0, ftype='fits', 
                  iname='z', index_range=[], interval=1, tag_pos=-1, **kwargs):
    
    import os
    import numpy as np
    
    exec_start()
    
        # load the images which are used as parameters
        # (see detailed description of the 'load_img_params' function)
    kwargs_img = load_img_params(base_dir, **kwargs)
    
        # get the list of all FITS files in the specified source directory
        # (including in its subdirectories)
    flist = file_list(src_dir, base_dir, ftype)
        
        # get the number of files in the list
    nfiles = len(flist)
    
        # create the keys array
    keys = []
    
        # initialize the batch and sequence variables
    bvar = {}
    svar = {}
    
        # initialize the last directory indication
    last_dir = ''
    
        # initialize the first processing indication
    first_proc = True
    
        # select the files to be processed
    do_proc = np.ones(nfiles, dtype='int')
    for i, name in enumerate(flist): 
        
            # get the file index
        fi = file_index(name, tag_pos)
        
            # if an index range is defined, test whether the current file is in range
        if index_range != []:
            if fi < index_range[0] or fi > index_range[1]:
                do_proc[i] = 0
                
            # if an interval is defined, test whether the current file needs to be processed
        if interval != 1:
            if (fi % interval) != 0: do_proc[i] = 0
    
        # get the count of files to be processed
    nfiles_proc = sum(do_proc)
    nprocessed = 0
    
        # loop for all files in the kept list
    for i, name in enumerate(flist): 
            
            # get the current directory
        cur_dir, _ = os.path.split(name)
        
            # if the directory has changed, reset the sequence variables
        if cur_dir != last_dir: svar = {}
        
            # get the file index
        fi = file_index(name, tag_pos)
        
            # if the current file has to be processed:
        if do_proc[i]:
            
                # load the source image
            src_img = get_img(name, os.path.join(base_dir, src_dir))
            
                # pass the file index to the processing and analysis functions
            kwargs_img['fi'] = fi
            
                # if a pre-processing sequence is defined
            if pre_proc != 0:
                
                    # execute the pre-processing sequence on the image
                src_img = exec_proc(src_img, seq=pre_proc, bvar=bvar, svar=svar, **kwargs_img)
                
                # exectue the analysis function to the image
            new_res = a_func(src_img, bvar=bvar, svar=svar, **kwargs_img)
            
                # add the index value
            for r in new_res:
                r[iname] = i
            
                # if this is the first iteration, get the keys list
            if first_proc:
                keys = list(new_res[0].keys())
                first_proc = False
                
                # write the results to the file
            write_results(dst_file, base_dir, new_res, keys, create_dir=True)
            
                # output the progess indication
            nprocessed = nprocessed + 1
            print('Processing (' + str(round(1000*(float(nprocessed))/nfiles_proc)/10) + '%)', end='\r')                                                           
        
            # set the last directory indication for the next iteration
        last_dir = cur_dir
    
       # output the completion indication
    print('')
    exec_end()
            
# ------------------------------------------------------------------
    
def consolidate(src_file, dst_dir, base_dir, values, cnames=['x','y'], vname='val', nname='name', 
                replace_nan=False, rebin_vals=[], max_lines=1e20):
    
    import os
    import numpy as np
    from neured.framework.img_utils import write_img
    
    def rebin(a, f):
        szx = a.shape[0]
        szy = a.shape[1]
        szxr = int(szx/f)
        szyr = int(szy/f)
        res = np.zeros([szxr,szyr])
        for x in np.arange(szxr):
            for y in np.arange(szyr):
                res[x,y] = np.nanmean(a[x*f:(x+1)*f,y*f:(y+1)*f])
        return res
    
    exec_start()          
    
    dim = len(cnames)
    ci = np.zeros(dim, dtype='int')
    imax = np.zeros(dim, dtype='int')
    imin = np.zeros(dim, dtype='int')
    
    data = []
    
    print('Reading ...', end='\r')
    
    data = read_file(src_file, base_dir, silent=False, max_lines=max_lines)
    nlines = len(data)
    
    print('')
    
        # get the index columns
    keys = data[0].split(';')
    
    for i in range(dim):
        ci[i] = keys.index(cnames[i])
        # get the name column
    cn = keys.index(nname)
        # get the value column
    cv = keys.index(vname)
    
    cmax = max(max(ci), cn, cv)
    
    ind = np.ones([dim, nlines-1], dtype=int)*float('nan')
    vals = np.zeros(nlines-1)
    names = ["" for i in range(nlines-1)]
    
    print('Parsing ...', end='\r')
    
    for i in range(1, nlines):
        
        fields = data[i].split(';')
        if len(fields) > cmax:
            names[i-1] = fields[cn]
            vals[i-1] = float(fields[cv])
            for j in range(dim):
                ind[j,i-1] = int(fields[ci[j]])
        if (i % 1000) == 0:
            print('Parsing (' + str(round(1000*(float(i))/nlines)/10) + '%)', end='\r')
            
    print('')
    data = []
    
    for i in range(dim):
        iv = ind[i,:]
        iv = iv[np.isfinite(iv)]
        imin[i] = min(iv)
        imax[i] = max(iv)
    
    """with open(src_name, newline='') as csvfile:
        reader = csv.DictReader(csvfile, delimiter=';')
        for row in reader:
            try:
                for i in range(dim):
                    if int(row[cnames[i]])+1 > imax[i]:
                        imax[i] = int(row[cnames[i]])+1
                    if int(row[cnames[i]])+1 < imin[i]:
                        imin[i] = int(row[cnames[i]])+1
                data.append(row)
            except ValueError:
                dummy = 0 # do nothing"""
                
    sz = imax - imin + np.ones(dim, dtype='int')
    
    print('Consolidating ...', end='\r')
    
    cdata = {}
    for val in values:
        cdata[val] = np.zeros(sz)
    
    for i, valname in enumerate(names):
        if valname in values:
            ivals = ind[:,i]
            if not np.isnan(ivals).any():
                (cdata[valname])[tuple((ivals-imin).astype(int))] = float(vals[i])
        if (i % 1000) == 0:
            print('Consolidating (' + str(round(1000*(float(i))/nlines)/10) + '%)', end='\r')
            
    print('')
    print('Writing results ...', end='\r')
    
    for i, val in enumerate(values):
        
        cdata_w = cdata[val]
        if replace_nan:
            cdata_w = np.nan_to_num(cdata_w)
        
        dst_file = os.path.join(dst_dir, val+'_img.fits')
        write_img(cdata_w, dst_file, base_dir)
        
        for rval in rebin_vals:
            cdata_r = rebin(cdata[val], rval)
            if replace_nan:
                cdata_r = np.nan_to_num(cdata_r)
            dst_file_r = add_tag(dst_file, 'r'+str(rval))
            #hdu = fits.PrimaryHDU(cdata_r)
            #hdu.writeto(dst_file_r)
            write_img(cdata_r, dst_file_r, base_dir)
        
        print('Writing results (' + str(round(1000*(float(i))/len(values))/10) + '%)', end='\r')
        
    print('')
                
    exec_end()
    
            
    

        
