Metadata-Version: 2.4
Name: pyMEAL
Version: 1.0.2
Summary: pyMEAL: Multi-Encoder-Augmentation-Aware-Learning
Home-page: https://github.com/ai-vbrain/pyMEAL
Author: The Hong Kong Center for Cerebrocardivascular Health Engineering (COCHE)
Author-email: amaradesa@connect.ust.hk
Project-URL: Source Code, https://github.com/ai-vbrain/pyMEAL
Project-URL: Bug Tracker, https://github.com/ai-vbrain/pyMEAL/issues
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: 3.8
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: tensorflow==2.9.0
Requires-Dist: matplotlib==3.9.2
Requires-Dist: SimpleITK==2.4.0
Requires-Dist: scipy==1.13.1
Requires-Dist: antspyx==0.5.4
Requires-Dist: numpy==1.23.5
Requires-Dist: imageio==2.36.0
Requires-Dist: nibabel==5.3.2
Requires-Dist: pillow==11.0.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: project-url
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# pyMEAL: Multi-Encoder-Augmentation-Aware-Learning

pyMEAL is a multi-encoder framework for augmentation-aware learning that accurately performs CT-to-T1-weighted MRI translation under diverse augmentations. It utilizes four dedicated encoders and three fusion strategies, concatenation (CC), fusion layer (FL), and controller block (BD), to capture augmentation-specific features. MEAL-BD outperforms conventional augmentation methods, achieving SSIM > 0.83 and PSNR > 25 dB in CT-to-T1w translation.

### Model Architecture Overview

<img width="611" alt="Image" src="https://github.com/user-attachments/assets/2ce4b937-3a9d-4157-859f-10e379843efe" />


Fig. 1:Model architecture for the model having no augmentation and traditional augmentation


<img width="683" alt="Image" src="https://github.com/user-attachments/assets/811fc579-a0d0-4ebf-bd2b-e47b48405647" />


Fig. 2: Model architecture for Multi-Stream with a Builder Controller block method (BD), Fusion layer (FL) and Encoder concatenation (CC)

## Dependecies
tensorflow

matplotlib

SimpleITK

scipy

antspyx


## Available Models

| Model ID | File Name                                      | Description                                 |
|----------|------------------------------------------------|---------------------------------------------|
| BD       | `builder1_mode1l1abW512_1_11211z1p1rt_.h5`     | Builder-based architecture model            |
| CC       | `best_moderRl_RHID2_1mo.h5`                    | Encoder-concatenation-based configuration   |
| FL       | `bestac22_mode3l_512m2_m21.h5`                 | Feature-level fusion-based model            |
| NA       | `direct7_11ag23f11.h5`                         | Direct training baseline model              |
| TA       | `best_modelaf2ndab7_221ag12g11.h5`             | traditional augmentation configuration model|

## Download Model Files

You can download any `.h5` file directly:

- [Download builder1_mode1l1abW512_1_11211z1p1rt_.h5](https://huggingface.co/AI-vBRAIN/pyMEAL/resolve/main/builder1_mode1l1abW512_1_11211z1p1rt_.h5)
- [Download best_moderRl_RHID2_1mo.h5](https://huggingface.co/AI-vBRAIN/pyMEAL/resolve/main/best_moderRl_RHID2_1mo.h5)
- [Download bestac22_mode3l_512m2_m21.h5](https://huggingface.co/AI-vBRAIN/pyMEAL/resolve/main/bestac22_mode3l_512m2_m21.h5)
- [Download direct7_11ag23f11.h5](https://huggingface.co/AI-vBRAIN/pyMEAL/resolve/main/direct7_11ag23f11.h5)
- [Download best_modelaf2ndab7_221ag12g11.h5](https://huggingface.co/AI-vBRAIN/pyMEAL/resolve/main/best_modelaf2ndab7_221ag12g11.h5)

or alternatively, you can use the following Python script to downlaod all the models from [Huggingface](https://huggingface.co/AI-vBRAIN/pyMEAL/edit/main/README.md).

```python
from huggingface_hub import hf_hub_download
import tensorflow as tf

my_folder = "./my_models"  # or any path you want

model_path = hf_hub_download(
    repo_id="AI-vBRAIN/pyMEAL",
    filename="builder1_mode1l1abW512_1_11211z1p1rt_.h5",  # or any other desired model in our Huggingface.
    repo_type="model",
    cache_dir=my_folder
)

# Load the model from that path
model = tf.keras.models.load_model(model_path, compile=False)
# Run inference
output = model.predict(input_data)
```
Here, `input_data` refers to a CT image, and the corresponding T1-weighted (T1w) image is predicted as the output.

For detailed instructions on how to use each module of the **pyMEAL** software, please refer to the [tutorial section on our GitHub repository](https://github.com/ai-vbrain/pyMEAL).

Finally, create and activate a virtual environment, then install **pyMEAL**.
```python
conda create -n pyMEAL python=3.9
conda activate pyMEAL
pip install pyMEAL
```



## How to get support?
For help, contact:

Dr. Ilyas (<amoiIyas@hkcoche.org>) or Dr. Maradesa (<amaradesa@hkcoche.org>)


