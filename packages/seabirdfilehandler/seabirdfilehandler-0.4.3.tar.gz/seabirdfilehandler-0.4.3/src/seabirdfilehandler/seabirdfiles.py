from pathlib import Path
from dataclasses import dataclass
from datetime import datetime, timezone
import xmltodict
import logging

logger = logging.getLogger(__name__)


@dataclass
class SeaBirdFile:
    """Base class to describe any kind of file generated by the Seasoft
    software. Such a file should be given as input to this class and the
    information it contains should subsequently be extracted and structured
    automatically. Various classes inherit from this one for a more file
    specific behaviour

    Parameters
    ----------

    Returns
    -------

    """

    def __init__(
        self,
        path_to_file: Path | str,
        only_header: bool = False,
    ):
        self.path_to_file = Path(path_to_file)
        self.file_name = self.path_to_file.stem
        self.file_dir = self.path_to_file.parent
        self.timestamp = datetime.now(timezone.utc)
        self.raw_file_data = []  # the text file input
        self.header = []  # the full file header
        self.sbe9_data = []  # device specific information
        self.metadata = {}  # non-SeaBird metadata
        self.metadata_list = []  # unstructured metadata for easier export
        self.data_table_description = []  # the column names and other info
        self.data_table_stats = {}
        self.data_table_names_and_spans = []
        self.data_table_misc = {}
        self.sensor_data = []
        self.sensors = {}  # xml-parsed sensor data
        self.processing_info = []  # everything after the sensor data
        self.data = []  # the data table
        self.file_data = self.raw_file_data  # variable file information
        with self.path_to_file.open("r", encoding="latin-1") as file:
            for line in file:
                self.raw_file_data.append(line)
                if only_header and line.startswith("*END*"):
                    break
        self.extract_file_information(only_header)
        if len(self.sensor_data) > 0:
            self.sensors = self.sensor_xml_to_flattened_dict(
                "".join(self.sensor_data)
            )

    def __str__(self) -> str:
        return "/n".join(self.file_data)

    def __repr__(self) -> str:
        return str(self.path_to_file.absolute())

    def __eq__(self, other) -> bool:
        return self.file_data == other.file_data

    def extract_file_information(self, only_header: bool = False):
        """Reads and structures all the different information present in the
        file. Lists and Dictionaries are the data structures of choice. Uses
        basic prefix checking to distinguish different header information.

        Parameters
        ----------

        Returns
        -------

        """
        self.metadata_list = []
        past_sensors = False
        for line in self.raw_file_data:
            line_prefix = line[:2]
            if line_prefix == "* ":
                self.header.append(line)
                self.sbe9_data.append(line[2:])
            elif line_prefix == "**":
                self.header.append(line)
                self.metadata_list.append(line[3:])
            elif line_prefix == "# ":
                self.header.append(line)
                if line[2:].strip()[0] == "<":
                    self.sensor_data.append(line[2:])
                    past_sensors = True
                else:
                    if past_sensors:
                        self.processing_info.append(line[2:])
                    else:
                        self.data_table_description.append(line[2:])
            elif line_prefix == "*E":
                self.header.append(line)
                if only_header:
                    break
            else:
                self.data.append(line)

        self.metadata = self.structure_metadata(self.metadata_list)
        self.differentiate_table_description()

    def differentiate_table_description(self):
        past_spans = False
        pre = []
        column_names = []
        column_value_spans = []
        post = []
        for line in self.data_table_description:
            if line.startswith("name"):
                # TODO: cuts off lines containing multiple '=' symbols
                column_names.append(line.split("=")[1].strip())
            elif line.startswith("span"):
                past_spans = True
                column_value_spans.append(line.split("=")[1].strip())
            else:
                if not past_spans:
                    pre.append(line)
                else:
                    post.append(line)
        assert len(column_names) == len(column_value_spans)
        self.data_table_stats = {
            line.split("=")[0].strip(): line.split("=")[1].strip()
            for line in pre
        }
        self.data_table_names_and_spans = [
            (name, span)
            for name, span in zip(column_names, column_value_spans)
        ]
        self.data_table_misc = {
            line.split("=")[0].strip(): line.split("=")[1].strip()
            for line in post
        }

    def sensor_xml_to_flattened_dict(
        self, sensor_data: str
    ) -> list[dict] | dict:
        """Reads the pure xml sensor input and creates a multilevel dictionary,
        dropping the first two dictionaries, as they are single entry only

        Parameters
        ----------

        Returns
        -------

        """
        full_sensor_dict = xmltodict.parse(sensor_data, process_comments=True)
        try:
            sensors = full_sensor_dict["Sensors"]["sensor"]
        except KeyError as error:
            logger.error(f"XML is not formatted as expected: {error}")
            return full_sensor_dict
        else:
            # create a tidied version of the xml-parsed sensor dict
            tidied_sensor_list = []
            for entry in sensors:
                # use comment value as type descriptor
                comment = entry["#comment"]
                split_comment = comment.split(",")
                new_entry = split_comment[1].strip()
                if split_comment[-1] == " 2":
                    new_entry += " 2"
                # remove second-level dict
                calibration_info = list(entry.values())[-1]
                try:
                    new_dict = {
                        "Channel": entry["@Channel"],
                        "SensorName": new_entry,
                        **calibration_info,
                    }
                except TypeError:
                    new_dict = {
                        "Channel": entry["@Channel"],
                        "SensorName": new_entry,
                        "Info": calibration_info,
                    }
                tidied_sensor_list.append(new_dict)
            return tidied_sensor_list

    def structure_metadata(self, metadata_list: list) -> dict:
        """Creates a dictionary to store the metadata that is added by using
        werums dship API.

        Parameters
        ----------
        metadata_list: list :
            a list of the individual lines of metadata found in the file

        Returns
        -------
        a dictionary of the lines of metadata divided into key-value pairs
        """
        out_dict = {}
        for line in metadata_list:
            try:
                (key, val) = line.split("=")
            except ValueError:
                out_dict["text"] = line
            else:
                out_dict[key.strip()] = val.strip()
        return out_dict
