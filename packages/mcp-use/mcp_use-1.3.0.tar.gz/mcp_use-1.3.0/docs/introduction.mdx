---
title: Introduction
description: "Welcome to mcp_use - The Open Source MCP Client Library"
---

<img className="block dark:hidden" src="/images/hero-light.png" alt="mcp_use Light Theme" />
<img className="hidden dark:block" src="/images/hero-dark.png" alt="mcp_use Dark Theme" />

## What is mcp_use?

mcp_use is an open source library that enables developers to connect any Language Learning Model (LLM) to any MCP server, allowing the creation of custom agents with tool access without relying on closed-source or application-specific clients.

## Key Features

<CardGroup cols={2}>
  <Card title="Open Source" icon="code" href="/essentials/installation">
    Connect any LLM to any MCP server without vendor lock-in
  </Card>
  <Card title="Flexible Configuration" icon="server" href="/essentials/configuration">
    Support for any MCP server through a simple configuration system
  </Card>
  <Card title="Easy Setup" icon="gear" href="/essentials/configuration">
    Simple JSON-based configuration for MCP server integration
  </Card>
  <Card title="Universal LLM Support" icon="robot" href="/essentials/llm-integration">
    Compatible with any LangChain-supported LLM provider
  </Card>
  <Card title="HTTP Connection" icon="network" href="/quickstart">
    Connect to MCP servers running on specific HTTP ports for web-based integrations
  </Card>
  <Card title="Dynamic Server Selection" icon="shuffle" href="/quickstart">
    Agents can dynamically choose the most appropriate MCP server for the task.
  </Card>
</CardGroup>

## Getting Started

<CardGroup cols={2}>
  <Card title="Installation" icon="download" href="/quickstart">
    Install mcp_use and set up your environment
  </Card>
  <Card title="Configuration" icon="book" href="/essentials/configuration">
    Learn how to configure mcp_use with your MCP server
  </Card>
</CardGroup>

## Streaming Agent Output

MCP-Use supports asynchronous streaming of agent output using the `astream` method. This allows you to receive incremental results, tool actions, and intermediate steps as they are generated by the agent.

### How to use

Call `agent.astream(query)` and iterate over the results asynchronously:

```python
async for chunk in agent.astream("your query here"):
    print(chunk["messages"], end="", flush=True)
```

Each chunk is a dictionary containing keys such as `actions`, `steps`, `messages`, and (on the last chunk) `output`. This enables real-time feedback and progress reporting in your applications.

See the README for more details and usage patterns.
