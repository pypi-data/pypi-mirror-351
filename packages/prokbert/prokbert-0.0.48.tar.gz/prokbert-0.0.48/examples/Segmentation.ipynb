{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d14bef41-1fb3-4991-8004-a263726a5c7a",
   "metadata": {},
   "source": [
    "# Preprocessing Sequence Data\n",
    "\n",
    "The initial stage of our pipeline involves two primary steps: segmentation and tokenization.\n",
    "\n",
    "Segmentation is depicted in the figure below. Genomic language models (GLMs) process limited-size chunks of sequence data, typically ranging from 0 to 4kb. Therefore, it's essential to divide the sequence into smaller parts, a process known as segmentation. Segmentation can be either contiguous, which splits the sequence into disjoint segments, or random, which involves randomly sampling segments of length L. \n",
    "\n",
    "The first practical step in segmentation is loading the sequence from a FASTA file. Often, it's also beneficial to include the reverse complement of the sequence.\n",
    "Segmentation process:\n",
    "\n",
    "<img src=\"https://github.com/nbrg-ppcu/prokbert/blob/main/assets/Figure2_segmentation.png?raw=true\" width=\"500\" height=\"300\" alt=\"Segmentation Process\"> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae52914-3859-425e-bb72-c633892f8bea",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset and create a segment database is a good practice\n",
    "\n",
    "The sequence processing is a computationaly expensive process considering the size of the available sequence data. It is a good practice the create a database that contains the processed sequences alongside with the labels, which we often refer to as segment database.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148f54d8-1ee9-43e7-8d3c-8947dc2518f7",
   "metadata": {},
   "source": [
    "# Loading the sequence data \n",
    "\n",
    "The `load_contigs` function efficiently handles sequence data from FASTA files, providing options to include reverse complements and sequence metadata. When the output is set to a DataFrame (`AsDataFrame=True`), the function organizes this data into a structured format, enhancing data accessibility and manipulation for downstream analyses.\n",
    "\n",
    "The resulting DataFrame consists of the following columns:\n",
    "- `sequence_id`: Unique identifier of the sequence (integer) if `is_add_sequence_id=True`.\n",
    "- `fasta_id`: identifier of the sequence, parsed from the fasta file.\n",
    "- `description`: Description or metadata associated with the sequence, typically extracted from the FASTA file.\n",
    "- `source_file`: Path of the source FASTA file.\n",
    "- `sequence`: Nucleotide sequence. Sequences are converted to uppercase if `to_uppercase=True`.\n",
    "- `orientation`: Indicates 'forward' for original sequences and 'reverse' for reverse complements if `adding_reverse_complement=True`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018ec73-f5e6-4ff8-bae1-c3b1618f003c",
   "metadata": {},
   "source": [
    "## Installation of ProkBERT (if needed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66218845-48e1-4e3e-af3c-b4e31411e363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProkBERT is already installed.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import prokbert\n",
    "    print(\"ProkBERT is already installed.\")\n",
    "except ImportError:\n",
    "    !pip install prokbert\n",
    "    print(\"Installed ProkBERT.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fddeeae-0083-4f49-b2d2-9db53a18b510",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 11:52:19,694 - INFO - Loading sequence data into memory!\n",
      "2023-11-12 11:52:19,695 - INFO - Since the fasta_files_list is a string, not a list, we convert it to a list.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>fasta_id</th>\n",
       "      <th>description</th>\n",
       "      <th>source_file</th>\n",
       "      <th>sequence</th>\n",
       "      <th>orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NC_000913.3</td>\n",
       "      <td>NC_000913.3 Escherichia coli str. K-12 substr....</td>\n",
       "      <td>/home/ligeti/github/prokbert/src/prokbert/data...</td>\n",
       "      <td>TATATTAGAAATGTCCGCGACCTTTCATACATACCACCGGTACGCC...</td>\n",
       "      <td>forward</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NC_000913.3</td>\n",
       "      <td>NC_000913.3 Escherichia coli str. K-12 substr....</td>\n",
       "      <td>/home/ligeti/github/prokbert/src/prokbert/data...</td>\n",
       "      <td>CCAGCAATGGTGAAAGGAAAATCCCCAGCAGGCTGGATGCCGACGC...</td>\n",
       "      <td>reverse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sequence_id     fasta_id  \\\n",
       "0            0  NC_000913.3   \n",
       "1            1  NC_000913.3   \n",
       "\n",
       "                                         description  \\\n",
       "0  NC_000913.3 Escherichia coli str. K-12 substr....   \n",
       "1  NC_000913.3 Escherichia coli str. K-12 substr....   \n",
       "\n",
       "                                         source_file  \\\n",
       "0  /home/ligeti/github/prokbert/src/prokbert/data...   \n",
       "1  /home/ligeti/github/prokbert/src/prokbert/data...   \n",
       "\n",
       "                                            sequence orientation  \n",
       "0  TATATTAGAAATGTCCGCGACCTTTCATACATACCACCGGTACGCC...     forward  \n",
       "1  CCAGCAATGGTGAAAGGAAAATCCCCAGCAGGCTGGATGCCGACGC...     reverse  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prokbert.sequtils import *\n",
    "import pkg_resources\n",
    "fasta_file = pkg_resources.resource_filename('prokbert','data/ESKAPE_sample.fasta')\n",
    "\n",
    "# This pandas dataframe holds the sequence data parsed from the fasta file\n",
    "sequences = load_contigs(fasta_file, IsAddHeader=True, adding_reverse_complement=True, AsDataFrame=True, to_uppercase=True, is_add_sequence_id=True)\n",
    "sequences.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b126631-6f46-4073-9c22-4288965d90c9",
   "metadata": {},
   "source": [
    "# Segmentation and tokenization\n",
    "\n",
    "The segmentation and tokenization process have multiple parameter sets. I.e. how large the segments, we want to sample, what is the minimum valid length, proportion of unknown tokens etc. \n",
    "The parameters are set by the config classes accordingly. \n",
    "\n",
    "\n",
    "The following table outlines the configuration parameters for ProkBERT, detailing their purpose, default values, types, and constraints.\n",
    "\n",
    "| Parameter | Description | Type | Default | Constraints |\n",
    "|-----------|-------------|------|---------|-------------|\n",
    "| **Segmentation** |\n",
    "| `type` | Defines the segmentation type. 'contiguous' means non-overlapping sections of the sequence are selected end-to-end. In 'random' segmentation, fragments are uniformly sampled from the original sequence. | string | `contiguous` | Options: `contiguous`, `random` |\n",
    "| `min_length` | Sets the minimum length for a segment. Any segment shorter than this will be discarded. | integer | 0 | Min: 0 |\n",
    "| `max_length` | Specifies the maximum length a segment can have. | integer | 512 | Min: 0 |\n",
    "| `coverage` | Indicates the expected average coverage of any position in the sequence by segments. This is only applicable for type=random. Note that because segments are uniformly sampled, the coverage might vary, especially at the sequence ends. | float | 1.0 | Min: 0.0, Max: 100.0 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b68e5-ecaf-46c6-b62e-511703dc8ffd",
   "metadata": {},
   "source": [
    "### Segmentation of sequence database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01b54cfb-4107-4de0-b387-4f3528b4967b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-12 11:52:23,256 - INFO - Checking input DataFrame!\n",
      "2023-11-12 11:52:23,257 - INFO - Checking input sequence_id is valid primary key in the DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>segment_start</th>\n",
       "      <th>segment_end</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>TATATTAGAAATGTCCGCGACCTTTCATACATACCACCGGTACGCC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>1024</td>\n",
       "      <td>TTATGCTATGAAAAAACATCTTTTAACTCTGACACTTTCCTCTATA...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   segment_id  sequence_id  segment_start  segment_end  \\\n",
       "0           0            0              0          512   \n",
       "1           1            0            512         1024   \n",
       "\n",
       "                                             segment  \n",
       "0  TATATTAGAAATGTCCGCGACCTTTCATACATACCACCGGTACGCC...  \n",
       "1  TTATGCTATGAAAAAACATCTTTTAACTCTGACACTTTCCTCTATA...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Segment a DataFrame:\n",
    "segmentation_params = {'max_length' : 512, # We split the sequence into L  \n",
    "                       'min_length' : 6,\n",
    "                       'type' : 'contiguous'} #default segmentation type\n",
    "segmentdb = segment_sequences(sequences, segmentation_params, AsDataFrame=True)\n",
    "segmentdb.head(2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfefe3a7-d993-466f-9a57-5370c5813740",
   "metadata": {},
   "source": [
    "### Segmentation of single sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "444b2c1e-916a-451c-809e-66492724d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'segment': 'ATCGATTT', 'segment_start': 0, 'segment_end': 8, 'sequence_id': nan}, {'segment': 'GCT', 'segment_start': 8, 'segment_end': 11, 'sequence_id': nan}]\n"
     ]
    }
   ],
   "source": [
    "from prokbert.config_utils import *\n",
    "# This class provide validated input parameters for segmentation and tokenization\n",
    "defconfig = SeqConfig() # For the detailed configarion parameters see: https://github.com/nbrg-ppcu/prokbert/blob/main/src/prokbert/configs/sequence_processing.yaml\n",
    "\n",
    "segmentation_params = {'max_length' : 8, # We split the sequence into L  \n",
    "                        'min_length' : 3,\n",
    "                         'type' : 'contiguous'} #default segmentation type\n",
    "# Setting up paramters for segmentation\n",
    "\n",
    "segmentation_params = defconfig.get_and_set_segmentation_parameters(segmentation_params)\n",
    "\n",
    "# Segment single sequence:\n",
    "segment_list = segment_sequence_contiguous('ATCGATTTGCT', segmentation_params)\n",
    "print(segment_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9d534-6ad9-42b0-82f8-6daca41ee4cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
