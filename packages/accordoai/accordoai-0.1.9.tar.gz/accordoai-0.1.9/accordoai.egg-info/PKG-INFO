Metadata-Version: 2.4
Name: accordoai
Version: 0.1.9
Summary: Chord prediction model from Accordo.ai
Home-page: https://github.com/NightKing-V/Chord-Classification-Model-accordo.ai-
Author: Valenteno Lenora
Author-email: valentenocavlenora@gmail.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: tensorflow>=2.0.0
Requires-Dist: numpy
Requires-Dist: librosa
Requires-Dist: music21
Requires-Dist: filetype
Requires-Dist: pandas
Requires-Dist: scipy
Requires-Dist: numpy
Requires-Dist: moviepy
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# ğŸ¼ Chord-Classification-Model-Accordo.ai

## ğŸ¤– Deep Learning for Automated Chord Recognition

This repository contains the research and implementation of deep learning models for real-time chord analysis and recognition, developed as part of the **Accordo.ai** project.

---

## ğŸ“Œ Project Overview

**Accordo.ai** is a system designed to provide real-time chord recognition from audio input. The project explores several deep learning approaches to accurately identify musical chords from audio signals, breaking down chord components into **root notes**, **bass notes**, **triads**, and **fourth notes**.

---

## ğŸ§  Models

Three main models were developed and evaluated:

### ğŸ¶ M1: Chroma-based Single Output Layer Model
- ğŸ“š **Dataset**: McGill Billboard
- ğŸ› **Features**: 12 chroma features
- ğŸ§© **Architecture**: Bi-LSTM with single output layer
- ğŸ§ª **Purpose**: Initial experimentation

### ğŸ¶ M2: Chroma-based Multi-Output Layer Model
- ğŸ“š **Dataset**: Isophonics (The Beatles)
- ğŸ› **Features**: 12 chroma features
- ğŸ§© **Architecture**: Bi-LSTM with four output layers (root, bass, triad, fourth)
- ğŸ§¬ **Augmentation**: Pitch shifting (Â±3 semitones)

### ğŸ¶ M3: CQT-based Multi-Output Layer Model
- ğŸ“š **Dataset**: Isophonics (The Beatles)
- ğŸ› **Features**: 192 CQT features (24 bins/octave Ã— 8 octaves)
- ğŸ§© **Architecture**: Bi-LSTM with four output layers (root, bass, triad, fourth)
- ğŸ§¬ **Augmentation**: Pitch shifting (Â±5 semitones), Gaussian noise
- âš™ï¸ **Extras**: Custom frequency weighting, batch normalization

---

## ğŸ—ƒï¸ Datasets

```
Burgoyne, J.A., Wild, J., & Fujinaga, I. (2011). An expert ground-truth set for audio 
chord recognition and music analysis. Proceedings of the 12th International 
Society for Music Information Retrieval Conference (ISMIR), 633â€“638. 
(McGill Billboard dataset. https://www.kaggle.com/datasets/jacobvs/mcgill
billboard) 
 
Harte, C., Sandler, M., Abdallah, S., & GÃ³mez, E. (2005). Symbolic representation 
of musical chords: A proposed syntax for text annotations. Proceedings of the 6th 
International Conference on Music Information Retrieval (ISMIR), 66â€“71. 
(Isophonics dataset. http://isophonics.net/content/reference-annotations
beatles) 

```
## âš™ï¸ Data Processing Pipeline

- ğŸ” **Feature Extraction**: Librosa (chroma & CQT)
- ğŸ¼ **Chord Standardization**: Enharmonic correction, consistent labeling
- ğŸ” **Stratified Splitting**: Balanced training/validation/test splits
- ğŸ§¬ **Augmentation**: Pitch shifting, noise injection
- ğŸ§  **Vectorization**: One-hot encoding of chord components

---

## ğŸ“ˆ Model Performance

Model **M3** showed the highest accuracy in testing and generalization. However, recognition of rare chords and noisy signals remains a challenge for all models.

---

## âš ï¸ Limitations & ğŸš€ Future Work

- ğŸ” Need for more diverse genre datasets
- ğŸ’» High computational requirements for training
- ğŸ¶ Difficulty with complex or ambiguous chords
- âš–ï¸ Sensitivity in multi-output predictions

**Planned improvements:**
1. Expanding dataset coverage
2. Enhancing post-processing logic
3. Exploring new model architectures (e.g., Transformers)
4. Real-time inference optimization

---

## ğŸ§° Dependencies

- TensorFlow / Keras  
- Librosa  
- NumPy  
- Pandas  
- Matplotlib  
- h5py  

---

## ğŸš€ Installation

```bash
# python library
pip install accordoai

# Clone the repository
git clone https://github.com/NightKing-V/Chord-Classification-Model-accordo.ai-.git


```
## ğŸ”– Citation

If you use this code or research in your work, please cite:
```
@misc{accordoai2025,
  author       = {Robalge Valenteno Lenora},
  title        = {Accordo.ai: Deep Learning for Automated Chord Recognition},
  year         = {2025},
  publisher    = {GitHub},
  url          = {https://github.com/NightKing-V/Chord-Classification-Model-accordo.ai-.git}
}
```
## ğŸ™Œ Credits
```
Aslanidis, T. A. (2020). Deep Learning in Audio Chord Estimation (Bachelor's 
thesis). Department of Informatics and Telecommunications, National and 
Kapodistrian University of Athens.  (https://github.com/taslanidis/Audio-Chord
Recognition) 

Harte, C. A. (2010). "Towards automatic extraction of harmony information from 
music signals." Proceedings of the 11th International Conference on Digital Audio 
Effects (DAFx-08).
```

## ğŸ“± Implmentations
```
Music Analysis System (AndroidApp + Backend)
https://github.com/NightKing-V/accordo.ai
```

## ğŸ‘¨â€ğŸ“ About the Author & Project Motivation

This research project was developed by Robalge Valenteno Lenora as part of the final year requirements for the BSc (Hons) Computer Science degree at the University of Plymouth.

Supervised by Dr. Mohamed Shafraz, the project explores how deep learning techniques can be applied to automate musical chord recognition and beat analysis â€” a task traditionally done manually or using rule-based systems. The motivation behind Accordo.ai stems from a passion for music and artificial intelligence, with a desire to bridge both fields to build intelligent tools for musicians, learners, and researchers.

This work not only contributes to the field of music information retrieval (MIR) but also demonstrates real-world application of modern AI engineering practices, including microservice architecture, containerization, and scalable machine learning deployment.

## ğŸ“œ License

[MIT License](LICENSE)
