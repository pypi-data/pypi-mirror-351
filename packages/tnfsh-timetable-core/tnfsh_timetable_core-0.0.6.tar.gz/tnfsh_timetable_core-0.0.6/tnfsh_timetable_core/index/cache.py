from typing import Optional
from pathlib import Path
import json
import asyncio
from datetime import datetime
from tnfsh_timetable_core.index.models import IndexResult, AllTypeIndexResult
from tnfsh_timetable_core.index.crawler import request_all_index, merge_results, re
from tnfsh_timetable_core.utils.logger import get_logger

logger = get_logger(logger_level="INFO")

# è¨˜æ†¶é«”å¿«å–
_memory_cache: Optional[AllTypeIndexResult] = None

# æœ¬åœ° JSON å¿«å–ç›®éŒ„
CACHE_DIR = Path(__file__).resolve().parent / "cache"
CACHE_DIR.mkdir(exist_ok=True)

async def load_from_memory() -> Optional[AllTypeIndexResult]:
    """å¾è¨˜æ†¶é«”è¼‰å…¥å¿«å–çš„ç´¢å¼•è³‡æ–™"""
    if _memory_cache is not None:
        logger.debug("âœ¨ å¾è¨˜æ†¶é«”å¿«å–å–å¾—ç´¢å¼•")
        return _memory_cache
    return None

async def save_to_memory(data: AllTypeIndexResult):
    """å°‡ç´¢å¼•è³‡æ–™å„²å­˜åˆ°è¨˜æ†¶é«”å¿«å–"""
    global _memory_cache
    _memory_cache = data
    logger.debug("âœ¨ å·²æ›´æ–°è¨˜æ†¶é«”å¿«å–")
    return _memory_cache

async def load_from_disk() -> Optional[AllTypeIndexResult]:
    """å¾ç£ç¢Ÿè¼‰å…¥å¿«å–çš„ç´¢å¼•è³‡æ–™"""
    path = CACHE_DIR / "all_type_index.json"
    try:
        if path.exists() and path.stat().st_size > 0:
            with open(path, encoding="utf-8") as f:
                data = json.load(f)
                result = AllTypeIndexResult.model_validate(data)
                # æ›´æ–°è¨˜æ†¶é«”å¿«å–
                await save_to_memory(result)
                logger.debug("ğŸ’¾ å¾æª”æ¡ˆè¼‰å…¥ç´¢å¼•å¿«å–")
                return result
    except Exception as e:
        logger.error(f"è®€å–å¿«å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
    return None

async def save_to_disk(data: AllTypeIndexResult):
    """å°‡ç´¢å¼•è³‡æ–™å„²å­˜åˆ°ç£ç¢Ÿå¿«å–"""
    path = CACHE_DIR / "all_type_index.json"
    try:
        with open(path, "w", encoding="utf-8") as f:
            f.write(data.model_dump_json(indent=4))
            logger.debug("ğŸ’¾ å·²æ›´æ–°æª”æ¡ˆå¿«å–")
    except Exception as e:
        logger.error(f"å„²å­˜å¿«å–æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

async def fetch_with_cache(base_url: str, refresh: bool = False) -> AllTypeIndexResult:
    """æ”¯æ´ä¸‰å±¤å¿«å–çš„æ™ºèƒ½è¼‰å…¥æ–¹æ³•
    
    Args:
        base_url (str): åŸºç¤ URL
        refresh (bool): æ˜¯å¦å¼·åˆ¶é‡æ–°è¼‰å…¥

    Returns:
        AllTypeIndexResult: ç´¢å¼•çµæœ
    """
    if not refresh:
        # 1. æª¢æŸ¥è¨˜æ†¶é«”å¿«å–
        if mem_cache := await load_from_memory():
            return mem_cache
        
        # 2. æª¢æŸ¥æª”æ¡ˆå¿«å–
        if disk_cache := await load_from_disk():
            await save_to_memory(disk_cache)
            return disk_cache
    
    # 3. å¾ç¶²è·¯ç²å–
    from tnfsh_timetable_core.index.crawler import fetch_all_index
    logger.info(f"ğŸŒ å¾ç¶²è·¯æŠ“å–ç´¢å¼•è³‡æ–™ï¼š{base_url}")
    all_index_result: AllTypeIndexResult = await fetch_all_index(base_url)

    # æ›´æ–°å¿«å–
    await save_to_memory(all_index_result)
    await save_to_disk(all_index_result)

    return all_index_result

if __name__ == "__main__":
    # For test cases, see: tests/test_index/test_cache.py
    pass
